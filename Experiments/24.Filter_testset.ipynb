{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import os\n",
    "from langchain_community.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter generated testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the dataset\n",
    "eval_dataset = Dataset.load_from_disk(\"eval_dataset\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "eval_df_syntethic = eval_dataset.to_pandas()\n",
    "eval_df_syntethic = eval_df_syntethic[[\"question\", \"answer\", \"source_doc\", \"context\", \"chunk_num\"]]\n",
    "print(len(eval_df_syntethic))\n",
    "display(eval_df_syntethic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the dataset\n",
    "eval_dataset_adjacent_chunks = Dataset.load_from_disk(\"eval_dataset_adjacent_chunks\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "eval_df_adjacent_chunks_syntethic = eval_dataset_adjacent_chunks.to_pandas()\n",
    "eval_df_adjacent_chunks_syntethic = eval_df_adjacent_chunks_syntethic[[\"question\", \"answer\", \"source_doc\", \"context\", \"chunk_num\"]]\n",
    "print(len(eval_df_adjacent_chunks_syntethic))\n",
    "display(eval_df_adjacent_chunks_syntethic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the dataset\n",
    "eval_dataset_random_chunks = Dataset.load_from_disk(\"eval_dataset_random_chunks\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "eval_df_random_chunks_syntethic = eval_dataset_random_chunks.to_pandas()\n",
    "eval_df_random_chunks_syntethic = eval_df_random_chunks_syntethic[[\"question\", \"answer\", \"source_doc\", \"context\", \"chunk_num\"]]\n",
    "print(len(eval_df_random_chunks_syntethic))\n",
    "display(eval_df_random_chunks_syntethic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS WITH NAN CHUNK NUM \n",
    "# Remove rows where 'column_name' contains NaN values\n",
    "eval_df_syntethic = eval_df_syntethic[eval_df_syntethic['chunk_num'].notna()]\n",
    "\n",
    "# Optionally, reset the index of the new dataframe (to avoid gaps in index after removal)\n",
    "eval_df_syntethic = eval_df_syntethic.reset_index(drop=True)\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "eval_df_syntethic['chunk_num'] = eval_df_syntethic['chunk_num'].apply(lambda x: [int(x)])\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(len(eval_df_syntethic))\n",
    "display(eval_df_syntethic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames\n",
    "df = pd.concat([\n",
    "    eval_df_random_chunks_syntethic, \n",
    "    eval_df_syntethic, \n",
    "    eval_df_adjacent_chunks_syntethic\n",
    "], ignore_index=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Initialize the Gemini model\n",
    "model_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro-latest\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def evaluate_pair(row):\n",
    "    # Costruisci un input strutturato per il modello\n",
    "    messages = [\n",
    "    SystemMessage(content=\"Sei un critico che valuta coppie di domande e risposte per una FAQ di un software gestionale. \\\n",
    "        Le coppie di domande e risposte devono soddisfare i seguenti criteri per essere considerate utili per valutare un chatbot destinato al supporto clienti di un software gestionale: \\\n",
    "        1. **Rilevanza**: Devono affrontare temi rilevanti per gli utenti di un software gestionale. \\\n",
    "        2. **Logicità e utilità**: Devono essere logiche e utili per fornire informazioni chiare e pratiche agli utenti. \\\n",
    "        Valuta la seguente coppia e decidi se è utile per testare un chatbot per il supporto clienti. Fornisci un feedback strutturato e dettagliato seguendo il formato specificato.\"),\n",
    "    HumanMessage(content=f\"**Domanda:** {row['question']}\\n**Risposta:** {row['answer']}\\n\\nValuta questa coppia di domanda-risposta e fornisci un feedback nel seguente formato:\\n\\\n",
    "        [Sì/No] \\\\ Spiegazione delle risposta:\\\n",
    "        - **Motivazione del perchè la coppia domanda-risposta è considerata utile o meno** \\\n",
    "        - **Motivazione sulla rilevanza**: [Breve spiegazione, se rilevante o non rilevante] \\\n",
    "        - **Motivazione sulla logicità**: [Breve spiegazione, se logica e utile o meno] \\founda \\\n",
    "        Indica anche eventuali miglioramenti necessari nella domanda o nella risposta.\")\n",
    "    ]\n",
    "\n",
    "    # Invia l'input strutturato al modello\n",
    "    response = model_gemini(messages)\n",
    "    return response.content[:8]  # Estrai l'output del modello\n",
    "\n",
    "# Apply the evaluation function to each row\n",
    "df[\"feedback\"] = df.progress_apply(evaluate_pair, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results to a CSV file\n",
    "df.to_csv(\"filtered_testset_withGemini.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Sì' is present in the 'feedback' column\n",
    "filtered_testset = df[df['feedback'].str.contains('Sì', na=False)]\n",
    "\n",
    "# Reset the index if desired\n",
    "filtered_testset = filtered_testset.reset_index(drop=True)\n",
    "filtered_testset = filtered_testset.drop(columns=\"feedback\")\n",
    "\n",
    "# Display the filtered dataframe\n",
    "display(filtered_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "extract = random.randint(0, len(filtered_testset))\n",
    "pprint.pprint(filtered_testset['question'][extract])\n",
    "pprint.pprint(filtered_testset['answer'][extract])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the best possible synthetic testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First prompt:\n",
    "\n",
    "Ti fornisco tre coppie di domande e risposte relative al contesto di un software gestionale. \\\n",
    "    Il tuo compito è selezionare la coppia migliore da utilizzare in un test set per valutare un chatbot basato su Retrieval-Augmented Generation (RAG). \\\n",
    "    Considera i seguenti criteri per scegliere la coppia migliore:\\\n",
    "    1. **Autocontenute**: La domanda e la risposta devono essere complete e non richiedere informazioni aggiuntive per essere comprese.\\\n",
    "    2. **Chiarezza**: La domanda deve essere chiara, sensata e fornire un contesto sufficiente per essere interpretata correttamente.\\\n",
    "    3. **Pertinenza**: La risposta deve essere direttamente correlata alla domanda e comprensibile per un utente che utilizza il software gestionale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "def gemini_decision(qas):\n",
    "    messages = [\n",
    "    SystemMessage(content=\"Ti fornisco tre coppie di domande e risposte relative al contesto di un software gestionale. \\\n",
    "    Il tuo compito è selezionare la coppia migliore da utilizzare in un test set per valutare un chatbot basato su Retrieval-Augmented Generation (RAG). \\\n",
    "    Considera i seguenti criteri per scegliere la coppia migliore: \\\n",
    "    1. **Autocontenute**: La domanda e la risposta devono essere complete e non richiedere informazioni aggiuntive per essere comprese. Assicurati che il contesto sia sufficientemente chiaro per capire senza ambiguità di cosa si stia parlando. \\\n",
    "    2. **Chiarezza**: La domanda deve essere formulata in modo chiaro, sensato, con una formulazione diretta ed essere realistica nel contesto del software gesionale. Non devono esserci termini vaghi o ambigui che possano confondere e deve essere plausibile che un utente ponga questa domanda. \\\n",
    "    3. **Pertinenza**: La risposta deve essere direttamente correlata alla domanda e comprensibile per un utente che utilizza il software gestionale. Escludi domande che riguardano visualizzazioni o operazioni generiche senza spiegazioni contestuali chiare. \\\n",
    "    Inoltre, **escludi domande troppo vaghe o che trattano aspetti di visualizzazione senza un contesto chiaro**, come quelle che chiedono genericamente \\\n",
    "    <quali informazioni sono visibili in una tabella> senza specificare il contesto o la funzione richiesta. \\\n",
    "    Evita anche domande che chiedono come visualizzare qualcosa senza spiegare di quale dato o schermata si sta parlando.\"),\n",
    "    HumanMessage(content=f\"Le tre coppie di domande e risposte sono: \\\n",
    "        1. Domanda: {qas[0][0]} - Risposta: {qas[0][1]}\\n \\\n",
    "        2. Domanda: {qas[1][0]} - Risposta: {qas[1][1]}\\n \\\n",
    "        3. Domanda: {qas[2][0]} - Risposta: {qas[2][1]}\\n \\\n",
    "        Seleziona **solo la domanda e la risposta migliori** in base ai criteri sopra descritti, senza alcun altro commento o spiegazione.\\\n",
    "        Rispondi nel formato: \\\n",
    "        Domanda: [domanda migliore]  \\\n",
    "        Risposta: [risposta migliore]\")\n",
    "    ] \n",
    "\n",
    "    response = model_gemini(messages)\n",
    "    response = response.content\n",
    "    pprint.pprint(response)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Usa una regex per estrarre la domanda e la risposta dalla risposta di Gemini\n",
    "    match = re.search(r\"Domanda:\\s*(.*?)\\s*Risposta:\\s*(.*)\", response, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        question = match.group(1).strip()\n",
    "        answer = match.group(2).strip()\n",
    "        return question, answer\n",
    "\n",
    "    return None, None\n",
    "\n",
    "# Step 2: Creare una copia del DataFrame\n",
    "df_copy = filtered_testset.copy()\n",
    "\n",
    "# Step 3: Lista per salvare le migliori coppie domanda-risposta\n",
    "best_qas = []\n",
    "\n",
    "# Step 4: Iterare ed estrarre gruppi di 3 domande-risposte\n",
    "while len(df_copy) >= 3:  # Continua solo se ci sono almeno 3 righe\n",
    "    # Estrai 3 righe casuali\n",
    "    sample = df_copy.sample(3)\n",
    "    \n",
    "    # Rimuovi le righe estratte dal DataFrame originale\n",
    "    df_copy = df_copy.drop(sample.index)\n",
    "    \n",
    "    # Crea una lista di tuple (domanda, risposta)\n",
    "    qas = list(zip(sample['question'], sample['answer']))\n",
    "\n",
    "    # Interazione con Gemini per scegliere la migliore coppia\n",
    "    question, answer = gemini_decision(qas)\n",
    "    \n",
    "    # Salva la coppia selezionata se valida\n",
    "    if question and answer:\n",
    "        best_qas.append((question, answer))\n",
    "\n",
    "# Step 5: Creare un nuovo DataFrame con le coppie migliori\n",
    "best_df = pd.DataFrame(best_qas, columns=['question', 'answer'])\n",
    "\n",
    "# Step 6: Salvare le coppie migliori in un file CSV\n",
    "best_df.to_csv('best_qas.csv', index=False)\n",
    "\n",
    "print(\"Le migliori coppie domanda-risposta sono state salvate in 'best_qas.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Normalize the 'question' column for comparison, keeping the original 'question' columns intact\n",
    "filtered_testset['normalized_question'] = filtered_testset['question'].str.strip().str.lower()\n",
    "best_df['normalized_question'] = best_df['question'].str.strip().str.lower()\n",
    "\n",
    "# Filter filtered_testset to keep rows with questions present in best_df (based on the normalized question)\n",
    "filtered_matching_questions = filtered_testset[filtered_testset['normalized_question'].isin(best_df['normalized_question'])]\n",
    "\n",
    "# Reset index of the filtered DataFrame\n",
    "filtered_matching_questions = filtered_matching_questions.reset_index(drop=True)\n",
    "\n",
    "# Drop the temporary normalized question column to retain the original question column\n",
    "filtered_matching_questions = filtered_matching_questions.drop(columns=['normalized_question'])\n",
    "\n",
    "# Display the filtered dataframe with original 'question' column\n",
    "display(filtered_matching_questions)\n",
    "\n",
    "# Optionally, save the filtered dataframe to a CSV file\n",
    "filtered_matching_questions.to_csv('filtered_matching_questions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_bianca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
