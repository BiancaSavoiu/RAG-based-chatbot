{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e501de323fbace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:11:33.723433Z",
     "start_time": "2024-10-02T08:11:33.705843Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from jupyter_core.version import pattern\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import contractions\n",
    "import random\n",
    "import pandas as pd\n",
    "import language_tool_python\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:11:34.048827Z",
     "start_time": "2024-10-02T08:11:33.871866Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_all_data_dict = \"./Files/cleaned_dataset.csv\"\n",
    "\n",
    "cleaned_data_df = pd.read_csv(filename_all_data_dict, names = ['file', 'text'], header = None)\n",
    "cleaned_data_df = cleaned_data_df.drop(index = 0)\n",
    "cleaned_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc35e0bbc408e25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:11:34.103249Z",
     "start_time": "2024-10-02T08:11:34.094708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list with all the values in the column 'text'\n",
    "text_list_preprocessed = cleaned_data_df['text'].tolist()\n",
    "file_list = cleaned_data_df['file'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51571443f67b7748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:11:34.517133Z",
     "start_time": "2024-10-02T08:11:34.501678Z"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(text_list_preprocessed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b9a473ba1e87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:11:34.741384Z",
     "start_time": "2024-10-02T08:11:34.694749Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_use_case(text):\n",
    "    # Define the regex pattern to match\n",
    "    pattern = r'(use case seu).*'\n",
    "    \n",
    "    # Remove all matches of the pattern\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "for i in range(len(text_list_preprocessed)):\n",
    "    text_list_preprocessed[i] = remove_use_case(text_list_preprocessed[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee23c459593b45b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:11:34.813875Z",
     "start_time": "2024-10-02T08:11:34.788867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary\n",
    "contraction_dictionary = {}\n",
    "\n",
    "# Read the contents of the file\n",
    "with open('italian_contractions.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read each line in the file\n",
    "    for line in file:\n",
    "        # Strip any leading/trailing whitespace and trailing commas\n",
    "        line = line.strip().rstrip(',')\n",
    "        \n",
    "        # Split the line into key and value based on the colon\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)  # Split only at the first colon\n",
    "            # Remove extra quotes and whitespace\n",
    "            \n",
    "            key = key.strip().strip('\"')\n",
    "            value = value.strip().strip('\"')\n",
    "            \n",
    "            # Add to the dictionary\n",
    "            contraction_dictionary[key] = value\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(len(contraction_dictionary),contraction_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d9c44f560b285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:14:47.724468Z",
     "start_time": "2024-10-02T08:14:46.485597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to replace contractions\n",
    "def expand_contractions(text, contraction_dict):\n",
    "    for contraction, expansion in contraction_dict.items():\n",
    "        # Use word boundaries to find the contraction as a whole word\n",
    "        text = re.sub(rf'\\b{re.escape(contraction)}\\b', expansion, text)\n",
    "    return text\n",
    "\n",
    "# Iterate through each document in text_list and replace contractions\n",
    "expanded_texts = [expand_contractions(text, contraction_dictionary) for text in text_list_preprocessed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc538cf220ce97fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:14:59.766886Z",
     "start_time": "2024-10-02T08:14:59.746552Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_whitespace(text):\n",
    "    \"\"\"\n",
    "    Reduces multiple consecutive whitespace characters to a single space.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text with excessive whitespace.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with reduced whitespace.\n",
    "    \"\"\"\n",
    "    # Replace one or more whitespace characters with a single space\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7726b8f4426ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T08:15:02.635794Z",
     "start_time": "2024-10-02T08:15:02.615429Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_any_special_characters(text):\n",
    "    # Do not remove the special characters of italian language, such as ù in più\n",
    "    regex = r\"[^a-zA-Z0-9\\s]\"\n",
    "    regex = r\"[^0-9a-zA-ZàèéìòùÀÈÉÌÒÙ\\s]\"\n",
    "    \n",
    "    cleaned_text = re.sub(regex, '', text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "for i in range(len(expanded_texts)):\n",
    "    expanded_texts[i] = remove_any_special_characters(expanded_texts[i])\n",
    "    expanded_texts[i] = normalize_whitespace(expanded_texts[i])\n",
    "    \n",
    "pprint.pprint(expanded_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc321d0cfb1b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the spaCy Italian model\n",
    "nlp = spacy.load('it_core_news_sm')\n",
    "\n",
    "# Initialize the spell checker for both Italian and English languages\n",
    "spell_it = SpellChecker(language='it')\n",
    "spell_en = SpellChecker(language='en')\n",
    "spell_en.word_frequency.add('panthera')\n",
    "\n",
    "correction_dict = {}\n",
    "suggestions_dict = {}\n",
    "\n",
    "# Function to check if the word is correct in either Italian or English\n",
    "def is_misspelled(word):\n",
    "    # If the word is misspelled in both Italian and English, it's considered incorrect\n",
    "    return word in spell_it.unknown([word]) and word in spell_en.unknown([word])\n",
    "\n",
    "# Process each text in the list\n",
    "for i, text in enumerate(tqdm(expanded_texts, desc=\"Checking text\")):\n",
    "    # Use spaCy to process the text (assuming no punctuation)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Tokenize the text into words (tokens)\n",
    "    words = [token.text for token in doc]\n",
    "    \n",
    "    # Identify misspelled words that are incorrect in both Italian and English\n",
    "    misspelled = [word for word in words if is_misspelled(word)]\n",
    "\n",
    "    correction_dict[i] = {}  # Nested dictionary for corrections\n",
    "    suggestions_dict[i] = {}  # Nested dictionary for suggestions\n",
    "    \n",
    "    # Correct the misspelled words\n",
    "    for word in misspelled:\n",
    "        # Get the most likely correction from the Italian dictionary\n",
    "        correction = spell_it.correction(word)\n",
    "        correction_dict[i][word] = correction\n",
    "        \n",
    "        # Get other suggestions (optional)\n",
    "        suggestions= spell_it.candidates(word)\n",
    "        suggestions_dict[i][word] = suggestions  # Combine suggestions from both dictionaries\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fa2ecabae3cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_suggestions(text, dictionary):\n",
    "    # Itera sulle coppie chiave-valore del dizionario\n",
    "    for _, suggestions in dictionary.items():\n",
    "        # Itera sulle parole e i loro suggerimenti nel sotto-dizionario\n",
    "        for word, suggestion in suggestions.items():\n",
    "            if (suggestion is not None) and len(suggestion) == 1 and len(word) > 3:    \n",
    "                sugg = str(suggestion).strip(\"{}'\")  \n",
    "                text = text.replace(word, sugg)    \n",
    "    return text\n",
    "\n",
    "# Esegui la funzione di espansione sulle prime due stringhe preprocessate\n",
    "cleaned_expanded_texts = [expand_suggestions(text, suggestions_dict) for text in expanded_texts]\n",
    "pprint.pprint(cleaned_expanded_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_apostrophe(text):\n",
    "    pattern = r\"\\'\"\n",
    "    \n",
    "    cleaned_text = re.sub(pattern, '’', text, flags=re.DOTALL)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lowercase text and remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    # Remove punctuation\n",
    "    import string\n",
    "    # Regex to identify any punctuation in the text\n",
    "    regex = '[' + string.punctuation + ']' #searching for a match with any of the characters inside the square brackets\n",
    "    result = re.sub(regex,' ',text)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply lowercase and punctuation removal to each cleaned text\n",
    "cleaned_text_list_to_save = [normalize_whitespace(remove_punctuation(modify_apostrophe(text))) for text in cleaned_expanded_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace contractions\n",
    "def expand_contractions(text, contraction_dict):\n",
    "    for contraction, expansion in contraction_dict.items():\n",
    "        # Use word boundaries to find the contraction as a whole word\n",
    "        text = re.sub(rf'\\b{re.escape(contraction)}\\b', expansion, text)\n",
    "    return text\n",
    "\n",
    "# Iterate through each document in text_list and replace contractions\n",
    "cleaned_text_list_to_save = [expand_contractions(text, contraction_dictionary) for text in cleaned_text_list_to_save]\n",
    "pprint.pprint(cleaned_text_list_to_save[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before removing any special characters try first to solve contractions\n",
    "# Find all the contractions in a text\n",
    "def find_words_with_apostrophe(text):\n",
    "    \"\"\"\n",
    "    This function finds all the words in the provided text that contain the contraction \"l'\".\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text from which to extract words.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of words containing \"l'\".\n",
    "    \"\"\"\n",
    "    # Define a regex pattern to match words containing \"'\"\n",
    "    pattern =r\"\\b\\w*’\\w*\\b|\\b\\w*'\\w*\\b\"\n",
    "    \n",
    "    # Use re.findall to get all matches\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Example usage\n",
    "words_with_apostr = []\n",
    "for text in cleaned_text_list_to_save:\n",
    "    words_with_apostr.extend(find_words_with_apostrophe(text))  # Use extend instead of append\n",
    "\n",
    "# Convert to a set to get unique words\n",
    "unique_words_with_apostr = set(words_with_apostr)\n",
    "\n",
    "print(unique_words_with_apostr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3bb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unique_words_with_apostr))\n",
    "pprint.pprint(unique_words_with_apostr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with 'file' and 'text' columns\n",
    "df = pd.DataFrame(columns=['file', 'text'])\n",
    "\n",
    "# Gradually add the data to the DataFrame\n",
    "for i in range(len(cleaned_text_list_to_save)):\n",
    "    df.loc[i] = [file_list[i], cleaned_text_list_to_save[i]]\n",
    "    \n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('./Files/final_dataset.csv', index=False)\n",
    "\n",
    "# Output the DataFrame to verify\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_bianca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
