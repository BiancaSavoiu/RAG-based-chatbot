{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Re-sized Base64 string\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"\n",
    "    Display base64 encoded string as image\n",
    "\n",
    "    :param img_base64:  Base64 string\n",
    "    \"\"\"\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_directory = os.path.abspath(os.path.join(path, os.pardir))\n",
    "output_dir = parent_directory + \"/Experiments/Extracted_Images\"\n",
    "file_path = output_dir + \"/figure-31-42.jpg\"\n",
    "pil_image = Image.open(file_path)\n",
    "image_b64 = convert_to_base64(pil_image)\n",
    "plt_img_base64(image_b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a Gemini API model.\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
    "\n",
    "# Prompt the model with text and the previously uploaded image.\n",
    "response = model.generate_content([pil_image, \"Descrivi la parte principale della finestra, nell'immagine fornita.\"])\n",
    "\n",
    "Markdown(\">\" + response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_base64_png(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Re-sized Base64 string\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"PNG\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plumber_path = parent_directory + \"/Experiments/Images\"\n",
    "file_path_plumber = plumber_path + \"/image_40.png\"\n",
    "image_pil_plumber = Image.open(file_path_plumber)\n",
    "image_b64 = convert_to_base64_png(image_pil_plumber)\n",
    "plt_img_base64(image_b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the model with text and the previously uploaded image.\n",
    "prompt = \"\"\"\n",
    "Descrivi la parte principale della finestra, nell'immagine fornita.\n",
    "Non descrivere schede e barre appartenenti al browser. Concentrati sulla videata del software.\n",
    "\"\"\"\n",
    "response = model.generate_content([image_pil_plumber, prompt])\n",
    "\n",
    "Markdown(\">\" + response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plumber_path = parent_directory + \"/Experiments/Images\"\n",
    "file_path_plumber = plumber_path + \"/image_41.png\"\n",
    "image_pil_plumber = Image.open(file_path_plumber)\n",
    "image_b64 = convert_to_base64_png(image_pil_plumber)\n",
    "plt_img_base64(image_b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the model with text and the previously uploaded image.\n",
    "prompt = \"\"\"\n",
    "Descrivi la parte principale della finestra, nell'immagine fornita.\n",
    "Non descrivere schede e barre appartenenti al browser. \n",
    "Concentrati sulla videata del software.\n",
    "\"\"\"\n",
    "response = model.generate_content([image_pil_plumber, prompt])\n",
    "\n",
    "Markdown(\">\" + response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstructured image extraction with placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.abspath(os.path.join(path, os.pardir))\n",
    "filepath = parent_directory + \"/Doc_Panthera/Gestionale/VEN_Contratti_Vendita_Ordini_Aperti.pdf\"\n",
    "print(\"Filepath:\", filepath)\n",
    "print(\"Output path:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import json\n",
    "\n",
    "# Parse the PDF\n",
    "elements = partition_pdf(\n",
    "    filepath,\n",
    "    extract_images_in_pdf=True,\n",
    "    strategy=\"hi_res\",\n",
    "    languages=['ita'],\n",
    "    extract_image_block_output_dir=output_dir\n",
    ")\n",
    "\n",
    "# Prepare the output structure and image metadata storage\n",
    "processed_elements = []\n",
    "image_metadata = {}\n",
    "\n",
    "for el in elements:\n",
    "    el_dict = el.to_dict()  # Convert element to a dictionary\n",
    "    el_type = el_dict.get(\"type\", None)  # Get the type of the element\n",
    "\n",
    "    if el_type == \"Image\":\n",
    "        # Get the image file path from the metadata\n",
    "        image_filename = el_dict.get(\"metadata\", {}).get(\"filename\")\n",
    "        image_path = os.path.join(output_dir, image_filename) if image_filename else None\n",
    "        \n",
    "        # Create a placeholder for the image\n",
    "        placeholder = f\"[IMAGE: {el_dict['element_id']}]\"\n",
    "        processed_elements.append(placeholder)\n",
    "        \n",
    "        # Save the image metadata for future processing\n",
    "        image_metadata[el_dict['element_id']] = {\n",
    "            \"metadata\": el_dict,\n",
    "            \"image_path\": image_path,\n",
    "        }\n",
    "    else:\n",
    "        # For other types, keep the text as is\n",
    "        processed_elements.append(el_dict.get(\"text\", \"\"))\n",
    "\n",
    "# Combine the text and placeholders into a single output\n",
    "output_text = \"\\n\".join(processed_elements)\n",
    "\n",
    "# Save the image metadata for later use\n",
    "with open(\"image_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(image_metadata, f, indent=2)\n",
    "\n",
    "# Print the text output with placeholders\n",
    "print(output_text)\n",
    "\n",
    "# Optionally save the text output\n",
    "with open(\"processed_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the image metadata\n",
    "with open(\"image_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    image_metadata = json.load(f)\n",
    "print(f\"There are {len(image_metadata)} images metadata extracted form the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_directory(directory_path):\n",
    "    # Get a list of all files and directories in the specified path\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "    return len(files)\n",
    "\n",
    "# Example usage\n",
    "directory_path = parent_directory + \"/Experiments/Extracted_Images\"\n",
    "file_count = count_files_in_directory(directory_path)\n",
    "print(f\"There are {file_count} images files in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to metadata and text files\n",
    "metadata_file = \"image_metadata.json\"\n",
    "processed_text_file = \"processed_output.txt\"\n",
    "final_output_file = \"final_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def process_images_and_get_descriptions(directory_path, model):\n",
    "    \"\"\"\n",
    "    Processes each .jpg image in the specified folder, opens it using PIL, \n",
    "    and calls the LLM model to get a description.\n",
    "\n",
    "    Args:\n",
    "    - directory_path: The path to the folder containing images.\n",
    "    - model: The LLM model that will generate descriptions for images.\n",
    "\n",
    "    Returns:\n",
    "    - descriptions: A dictionary where the keys are image filenames \n",
    "      and the values are the generated descriptions.\n",
    "    \"\"\"\n",
    "    descriptions = {}\n",
    "\n",
    "    # Loop through the directory and find all .jpg files\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith('.jpg'):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            # Open the image using PIL\n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    # Generate description using the LLM model\n",
    "                    print(f\"Processing image: {filename}\")\n",
    "                    response = model.generate_content(\n",
    "                        [image_path, \"Descrivi la parte principale della finestra, nell'immagine fornita.\"]\n",
    "                    )\n",
    "                    \n",
    "                    # Extract description from the model's response\n",
    "                    description = response.text\n",
    "                    descriptions[filename] = description\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                descriptions[filename] = \"Error processing image\"\n",
    "\n",
    "    return descriptions\n",
    "\n",
    "descriptions = process_images_and_get_descriptions(directory_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "def extract_image_path_and_id_from_element(element):\n",
    "    \"\"\"\n",
    "    Extracts the 'image_path' and 'element_id' from a given element.\n",
    "\n",
    "    Args:\n",
    "    - element: A dictionary representing an element containing metadata.\n",
    "\n",
    "    Returns:\n",
    "    - (image_path, element_id): A tuple containing the image path and element id if present, else None for each.\n",
    "    \"\"\"\n",
    "    # Check if the element contains 'metadata', 'image_path', and 'element_id'\n",
    "    if 'metadata' in element:\n",
    "        image_path = element['metadata'].get('image_path')\n",
    "        element_id = element.get('element_id')\n",
    "        \n",
    "        # Return both image_path and element_id if they are present\n",
    "        if image_path and element_id:\n",
    "            return image_path, element_id\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_image_paths_and_ids(metadata_file):\n",
    "    \"\"\"\n",
    "    Extracts the 'image_path' and 'element_id' for each element in the image metadata JSON file.\n",
    "\n",
    "    Args:\n",
    "    - metadata_file: The path to the image metadata JSON file.\n",
    "\n",
    "    Returns:\n",
    "    - image_data: A list of tuples containing the image path and element id.\n",
    "    \"\"\"\n",
    "    image_data = []\n",
    "\n",
    "    try:\n",
    "        # Load the image metadata from the JSON file\n",
    "        with open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            image_metadata = json.load(f)\n",
    "        \n",
    "        # Iterate through the elements in the metadata and extract the image_path and element_id\n",
    "        for element in image_metadata.values():\n",
    "            # Use the extract_image_path_and_id_from_element function to get both the image path and element id\n",
    "            data = extract_image_path_and_id_from_element(element)\n",
    "            if data:\n",
    "                image_data.append(data)\n",
    "            else:\n",
    "                print(f\"Warning: No 'image_path' or 'element_id' found for element.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading metadata file: {e}\")\n",
    "\n",
    "    return image_data\n",
    "\n",
    "# Example usage:\n",
    "metadata_file = \"image_metadata.json\"  # Path to the image metadata file\n",
    "image_data = extract_image_paths_and_ids(metadata_file)\n",
    "\n",
    "# Print extracted image paths and element ids\n",
    "for image_path, element_id in image_data:\n",
    "    print(f\"Image Path: {os.path.basename(image_path)}, Element ID: {element_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def integrate_descriptions(metadata_file, descriptions, processed_output_path, final_output_path):\n",
    "    \"\"\"\n",
    "    Integrates image descriptions into the text by replacing [IMAGE: element_id] placeholders.\n",
    "\n",
    "    Args:\n",
    "    - metadata_file: Path to the metadata JSON file containing image_path and element_id.\n",
    "    - descriptions: Dictionary where keys are image filenames, and values are descriptions.\n",
    "    - processed_output_path: Path to the text file containing placeholders.\n",
    "    - final_output_path: Path to save the final text with descriptions integrated.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Step 1: Create a mapping of element_id to descriptions\n",
    "    element_id_to_description = {}\n",
    "\n",
    "    # Load metadata\n",
    "    with open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        image_metadata = json.load(f)\n",
    "\n",
    "    # Map element_id to descriptions\n",
    "    for element in image_metadata.values():\n",
    "        if 'metadata' in element:\n",
    "            image_path = element['metadata'].get('image_path')\n",
    "            element_id = element.get('element_id')\n",
    "            if image_path and element_id:\n",
    "                # Extract filename from image_path\n",
    "                filename = os.path.basename(image_path)\n",
    "                # Get description if available\n",
    "                description = descriptions.get(filename)\n",
    "                if description:\n",
    "                    element_id_to_description[element_id] = description\n",
    "\n",
    "    # Step 2: Replace placeholders in the processed_output text\n",
    "    with open(processed_output_path, \"r\", encoding=\"utf-8\") as processed_file:\n",
    "        processed_text = processed_file.read()\n",
    "\n",
    "    # Replace [IMAGE: element_id] placeholders with descriptions\n",
    "    for element_id, description in element_id_to_description.items():\n",
    "        placeholder = f\"[IMAGE: {element_id}]\"\n",
    "        processed_text = processed_text.replace(placeholder, description)\n",
    "\n",
    "    # Step 3: Write the final output to a file\n",
    "    with open(final_output_path, \"w\", encoding=\"utf-8\") as final_file:\n",
    "        final_file.write(processed_text)\n",
    "\n",
    "    print(f\"Descriptions successfully integrated into {final_output_path}\")\n",
    "    return processed_text\n",
    "\n",
    "metadata_file = \"image_metadata.json\"\n",
    "processed_output_path = \"processed_output.txt\"\n",
    "final_output_path = \"final_output.txt\"\n",
    "\n",
    "processed_text = integrate_descriptions(metadata_file, descriptions, processed_output_path, final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_name = \"Prova\"\n",
    "# Save the updated text to a new CSV file with file_name and updated_text as columns\n",
    "csv_name = \"Gemini_augmented_dataset.csv\"\n",
    "with open(csv_name, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=\"|\")\n",
    "    csv_writer.writerow([\"file_name\", \"updated_text\"])  # Write header\n",
    "    csv_writer.writerow([file_name, processed_text])  # Write data row\n",
    "\n",
    "print(\"Text updated with image descriptions and saved to 'Gemini_augmented_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset for RAG\n",
    "import pandas as pd\n",
    "\n",
    "csv_name = \"Gemini_augmented_dataset.csv\"\n",
    "data_df = pd.read_csv(csv_name, names = ['file_name', 'updated_text'], delimiter=\"|\")\n",
    "data_df = data_df.drop(index = 0)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "import pprint\n",
    "\n",
    "loader = DataFrameLoader(data_df, page_content_column=\"updated_text\")\n",
    "docs_data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents and keep track of chunk numbers within each document\n",
    "splits = []\n",
    "for doc in docs_data:\n",
    "    # Split each document into chunks\n",
    "    doc_chunks = text_splitter.split_documents([doc])\n",
    "    \n",
    "    # Add chunk number as metadata\n",
    "    for chunk_num, chunk in enumerate(doc_chunks):\n",
    "        chunk.metadata[\"chunk_number\"] = chunk_num + 1  # Adding 1 to start counting from 1\n",
    "        splits.append(chunk)\n",
    "\n",
    "# Print the first few splits with chunk numbers\n",
    "pprint.pprint(splits[0:6])\n",
    "pprint.pprint(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "model_fp16 = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M3EmbeddingFP16:\n",
    "    def embed_documents(self, texts):\n",
    "        return model_fp16.encode(texts)['dense_vecs']\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        return self.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embd = M3EmbeddingFP16()\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embd)\n",
    "vectorstore.save_local(\"gemini_trial_VEN_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Come posso decidere se nel calcolo della percentuale di saturazione del contratto vadano considerate anche la quantità in previsione?\"\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"\n",
    "Comportati come un assistente che risponde alle domande del cliente.\n",
    "Rispondi alla domanda basandoti solo sui seguenti documenti: {context}\n",
    "Rispondi in modo conciso e chiaro, spiegando passo passo al cliente le azioni necessarie da effettuare.\n",
    "Se possibile, dai indicazioni dettagliate al cliente, su come risolvere il problema o effettuare l'azione desiderata.\n",
    "Evita troppe ripetizioni nella risposta fornita.\n",
    "Quando spieghi che cosa è o cosa significa un certo elemento richiesto, non parlarne come se fosse un problema.\n",
    "\n",
    "In caso di più domande rispondi solo a quelle inerenti alla documentazione e rimani a disposizione per altre domande sull'argomento, specificando,\n",
    "invece, che le altre domande non sono state trovate pertinenti in questo contesto.\n",
    "\n",
    "Domanda relativa al software Panthera: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM - the used model\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "# max_token\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "pprint.pprint(rag_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_bianca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
