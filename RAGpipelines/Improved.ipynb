{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved Naive RAG:\n",
    "- image augmented dataset\n",
    "- simple preprocessing\n",
    "- optimized recursive chunking (size 1500, overlap 150)\n",
    "- hybrid retriever - dense vectors and TF-IDF with k = 4 (sparse, weight 0.2) + 2 (dense, weight 0.8)\n",
    "- bge-m3\n",
    "- no question re-writing\n",
    "- no reranking\n",
    "- no RRF\n",
    "- prompting\n",
    "- Gemini LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro-latest\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset - vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "model_fp16 = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "class M3EmbeddingFP16:\n",
    "    def embed_documents(self, texts):\n",
    "        return model_fp16.encode(texts)['dense_vecs']\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        return self.embed_documents(texts)\n",
    "    \n",
    "embd = M3EmbeddingFP16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains the documents without any data preprocessing steps\n",
    "vectorstore = FAISS.load_local(\"cleaned_recursive_augmented_faiss_index\", embd, allow_dangerous_deserialization=True)\n",
    "vectorstore, vectorstore.index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "csv_input_path = os.path.dirname(path) + \"/augmented_dataset_final_outputs.csv\"\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_input_path, encoding='utf-8')\n",
    "\n",
    "# Display the first few rows of the DataFrame to check the contents\n",
    "display(df)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "loader = DataFrameLoader(df, page_content_column=\"Text\")\n",
    "docs_data = loader.load()\n",
    "\n",
    "import importlib\n",
    "import Data_preprocessing\n",
    "importlib.reload(Data_preprocessing)\n",
    "\n",
    "# Initialize the Preprocessing object\n",
    "preprocessing = Data_preprocessing.Preprocessing()\n",
    "\n",
    "for doc in docs_data:\n",
    "    doc.page_content = preprocessing.clean_text_template(doc.page_content)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
    "\n",
    "splits = text_splitter.split_documents(docs_data)\n",
    "pprint.pprint(splits[0:6])\n",
    "pprint.pprint(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import TFIDFRetriever, EnsembleRetriever\n",
    "\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "sparse_retriever = TFIDFRetriever.from_documents(splits)\n",
    "sparse_retriever.k =  4\n",
    "\n",
    "retriever = EnsembleRetriever(retrievers=[sparse_retriever, dense_retriever], weights=[0.2, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Gemini RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template_RAG_generation = \"\"\"   \n",
    "Comportati come un assistente che risponde alle domande del cliente.   \n",
    "Rispondi alla domanda basandoti solo sui seguenti documenti: {context}.\n",
    "\n",
    "Rispondi in modo conciso e chiaro, spiegando passo passo al cliente le azioni necessarie da effettuare.   \n",
    "Se possibile, dai indicazioni dettagliate al cliente, su come risolvere il problema o effettuare l'azione desiderata. \n",
    "Evita troppe ripetizioni nella risposta fornita.\n",
    "Quando spieghi che cosa è o cosa significa un certo elemento richiesto, non parlarne come se fosse un problema.\n",
    "\n",
    "In caso di più domande rispondi solo a quelle inerenti alla documentazione e rimani a disposizione per altre domande sull'argomento,\n",
    "specificando, invece, che le altre domande non sono state trovate pertinenti in questo contesto.\n",
    "\n",
    "Domanda relativa al software Panthera: {question} \n",
    "\"\"\"\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_template(template_RAG_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def baseline_format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "basic_rag_chain = (\n",
    "    {\"context\": retriever | baseline_format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generation_prompt\n",
    "    | model_gemini\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the improved Basic RAG pipeline on a small testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved CSV file\n",
    "eval_df = pd.read_csv('filtered_matching_questions.csv')\n",
    "\n",
    "# Display the first few rows of the loaded DataFrame\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import E2E_Evaluation_metrics\n",
    "importlib.reload(E2E_Evaluation_metrics)\n",
    "from E2E_Evaluation_metrics import RAGEvaluator\n",
    "from E2E_Evaluation_metrics import SemScoreQueryRewriting\n",
    "\n",
    "evaluator = RAGEvaluator()\n",
    "semscore = SemScoreQueryRewriting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_answers(generation_chain, df, model_name, chunking_type, preprocessing, retriever, techniques):\n",
    "    # Create a copy of the original dataframe to avoid modifying it\n",
    "    new_df = df.copy()\n",
    "    new_df['generated_answer'] = None\n",
    "    new_df['model'] = None\n",
    "    new_df['chunking'] = None\n",
    "    new_df['preprocessing'] = None\n",
    "    new_df['retriever'] = None\n",
    "    new_df['advanced_techniques'] = None\n",
    "\n",
    "    # Iterate through the dataframe and generate answers\n",
    "    for idx, elem in new_df.iterrows():\n",
    "        question = elem[\"question\"]\n",
    "        new_df.at[idx, 'generated_answer'] = generation_chain.invoke(question) \n",
    "        new_df.at[idx, 'model'] = model_name\n",
    "        new_df.at[idx, 'chunking'] = chunking_type\n",
    "        new_df.at[idx, 'preprocessing'] = preprocessing\n",
    "        new_df.at[idx, 'retriever'] = retriever\n",
    "        new_df.at[idx, 'advanced_techniques'] = techniques\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_answers(basic_rag_chain, eval_df, 'Gemini', 'Recursive', 'Simple Preprocessing', 'Dense-6', 'No advanced techniques')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['BLEU', 'ROUGE-2', 'ROUGE-L', 'BERT P', 'BERT R', 'Perplexity', 'Diversity']\n",
    "\n",
    "def evaluate_responses(eval_df, evaluator):\n",
    "    results = []\n",
    "    for _, row in eval_df.iterrows():\n",
    "        response = row['generated_answer']\n",
    "        reference = row['answer']\n",
    "        \n",
    "        # Check if either response or reference is empty, and skip this row\n",
    "        if not response or not reference:\n",
    "            continue\n",
    "        \n",
    "        # Evaluate and store the results\n",
    "        evaluation = evaluator.evaluate_all(response, reference)\n",
    "        results.append(evaluation)\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "def process_evaluation_and_metrics(data_frame, model_name, evaluator = evaluator, semscore = semscore, columns_to_drop = columns_to_drop):\n",
    "    \"\"\"\n",
    "    Evaluate responses, compute semantic scores, and merge results into a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data_frame (pd.DataFrame): The input DataFrame with original and rewritten questions.\n",
    "    - evaluator (object): The evaluation object to compute BLEU, ROUGE, etc.\n",
    "    - semscore (object): The semantic score computation object.\n",
    "    - model_name (str): Name of the model for semantic similarity scoring.\n",
    "    - columns_to_drop (list): List of columns to drop from the evaluated DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Updated DataFrame with evaluation metrics and semantic scores.\n",
    "    \"\"\"\n",
    "    # Step 1: Evaluate responses\n",
    "    eval_df = evaluate_responses(data_frame, evaluator)\n",
    "    \n",
    "    # Step 2: Drop unnecessary columns\n",
    "    eval_df = eval_df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "    # Step 3: Compute semantic scores\n",
    "    reference = \"answer\"\n",
    "    response = \"generated_answer\"\n",
    "    cosine_similarities_bge, _ = semscore.compute_sem_score(data_frame, model_name=model_name, reference=reference, response=response)\n",
    "    eval_df[\"SemScore\"] = cosine_similarities_bge[\"Cosine_Similarity\"]\n",
    "\n",
    "    # Step 4: Merge original DataFrame with evaluation metrics\n",
    "    merged_df = pd.concat([data_frame, eval_df], axis=1)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = process_evaluation_and_metrics(\n",
    "    data_frame=df, \n",
    "    model_name='BAAI/bge-m3'\n",
    ")\n",
    "\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the filtered dataframe to a CSV file\n",
    "eval_df.to_csv('ResultsOnTestset/Improved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_average_value(df, output_file):\n",
    "    # Compute the averages\n",
    "    mean_rouge = df['ROUGE-1'].mean()\n",
    "    mean_bert = df['BERT F1'].mean()\n",
    "    mean_sem = df['SemScore'].mean()\n",
    "\n",
    "    # Get model and other details\n",
    "    model = df['model'].unique()\n",
    "    chunking = df[\"chunking\"].unique()\n",
    "    preprocessing = df['preprocessing'].unique()\n",
    "    retriever = df['retriever'].unique()\n",
    "    advanced_techniques = df[\"advanced_techniques\"].unique()\n",
    "\n",
    "    # Create a dictionary of the results\n",
    "    results = {\n",
    "        'Model': model,\n",
    "        'Chunking': chunking,\n",
    "        'Preprocessing': preprocessing,\n",
    "        'Retriever': retriever,\n",
    "        'Advanced Techniques': advanced_techniques,\n",
    "        'Mean ROUGE-1': mean_rouge,\n",
    "        'Mean BERT F1': mean_bert,\n",
    "        'Mean SemScore': mean_sem\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    results_df = pd.DataFrame([results])\n",
    "\n",
    "    # Append the results to the CSV file (if it exists, otherwise create a new one)\n",
    "    results_df.to_csv(output_file, mode='a', header=not pd.io.common.file_exists(output_file), index=False)\n",
    "\n",
    "    # Print the results (optional)\n",
    "    print(\"Model:\", model, \"with chunking of type:\", chunking, \"that uses\", \n",
    "          preprocessing, retriever, advanced_techniques)\n",
    "    print(f\"Mean ROUGE-1: {mean_rouge}\")\n",
    "    print(f\"Mean BERT F1: {mean_bert}\")s\n",
    "    print(f\"Mean SemScore: {mean_sem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_value(eval_df, \"ResultsMeanScore/Improved.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_bianca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
