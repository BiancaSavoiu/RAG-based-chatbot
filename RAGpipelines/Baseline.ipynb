{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic RAG pipeline with Gemini: \n",
    "- no image augmented dataset\n",
    "- no pre-processing\n",
    "- recursive chunking with baseline values, big chunks of 3000 size and 500 overlap\n",
    "- dense retriever with k = 6\n",
    "- bge-m3\n",
    "- no question re-writing\n",
    "- no reranking\n",
    "- no RRF\n",
    "- simple prompt, without preprocessing\n",
    "- Gemini LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro-latest\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset - vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "model_fp16 = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "class M3EmbeddingFP16:\n",
    "    def embed_documents(self, texts):\n",
    "        return model_fp16.encode(texts)['dense_vecs']\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        return self.embed_documents(texts)\n",
    "    \n",
    "embd = M3EmbeddingFP16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains the documents without any data preprocessing steps\n",
    "vectorstore = FAISS.load_local(\"local_model_index\", embd, allow_dangerous_deserialization=True)\n",
    "vectorstore, vectorstore.index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - Gemini Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "first_basic_template = \"\"\"   \n",
    "Comportati come un assistente che risponde alle domande del cliente.   \n",
    "Rispondi alla domanda basandoti solo sui seguenti documenti: {context}.   \n",
    "\n",
    "Rispondi in modo conciso e chiaro, spiegando passo passo al cliente le azioni necessarie da effettuare.   \n",
    "Se possibile, dai indicazioni dettagliate al cliente, su come risolvere il problema o effettuare l'azione desiderata.\n",
    "\n",
    "Domanda relativa al software Panthera: {question}   \n",
    "\"\"\"\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_template(first_basic_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def baseline_format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "basic_rag_chain = (\n",
    "    {\"context\": retriever | baseline_format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generation_prompt\n",
    "    | model_gemini\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the baseline Basic RAG pipeline on a small testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved CSV file\n",
    "eval_df = pd.read_csv('filtered_matching_questions.csv')\n",
    "\n",
    "# Display the first few rows of the loaded DataFrame\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import E2E_Evaluation_metrics\n",
    "importlib.reload(E2E_Evaluation_metrics)\n",
    "from E2E_Evaluation_metrics import RAGEvaluator\n",
    "from E2E_Evaluation_metrics import SemScoreQueryRewriting\n",
    "\n",
    "evaluator = RAGEvaluator()\n",
    "semscore = SemScoreQueryRewriting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_answers(generation_chain, df, model_name, chunking_type, preprocessing, retriever, techniques):\n",
    "    # Create a copy of the original dataframe to avoid modifying it\n",
    "    new_df = df.copy()\n",
    "    new_df['generated_answer'] = None\n",
    "    new_df['model'] = None\n",
    "    new_df['chunking'] = None\n",
    "    new_df['preprocessing'] = None\n",
    "    new_df['retriever'] = None\n",
    "    new_df['advanced_techniques'] = None\n",
    "\n",
    "    # Iterate through the dataframe and generate answers\n",
    "    for idx, elem in new_df.iterrows():\n",
    "        question = elem[\"question\"]\n",
    "        new_df.at[idx, 'generated_answer'] = generation_chain.invoke(question) \n",
    "        new_df.at[idx, 'model'] = model_name\n",
    "        new_df.at[idx, 'chunking'] = chunking_type\n",
    "        new_df.at[idx, 'preprocessing'] = preprocessing\n",
    "        new_df.at[idx, 'retriever'] = retriever\n",
    "        new_df.at[idx, 'advanced_techniques'] = techniques\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_answers(basic_rag_chain, eval_df, 'Gemini', 'Recursive Baseline', 'No Preprocessing and no augmentation', 'Dense-6', 'No advanced techniques, but prompt engineering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['BLEU', 'ROUGE-2', 'ROUGE-L', 'BERT P', 'BERT R', 'Perplexity', 'Diversity']\n",
    "\n",
    "def evaluate_responses(eval_df, evaluator):\n",
    "    results = []\n",
    "    for _, row in eval_df.iterrows():\n",
    "        response = row['generated_answer']\n",
    "        reference = row['answer']\n",
    "        \n",
    "        # Check if either response or reference is empty, and skip this row\n",
    "        if not response or not reference:\n",
    "            continue\n",
    "        \n",
    "        # Evaluate and store the results\n",
    "        evaluation = evaluator.evaluate_all(response, reference)\n",
    "        results.append(evaluation)\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "def process_evaluation_and_metrics(data_frame, model_name, evaluator = evaluator, semscore = semscore, columns_to_drop = columns_to_drop):\n",
    "    \"\"\"\n",
    "    Evaluate responses, compute semantic scores, and merge results into a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data_frame (pd.DataFrame): The input DataFrame with original and rewritten questions.\n",
    "    - evaluator (object): The evaluation object to compute BLEU, ROUGE, etc.\n",
    "    - semscore (object): The semantic score computation object.\n",
    "    - model_name (str): Name of the model for semantic similarity scoring.\n",
    "    - columns_to_drop (list): List of columns to drop from the evaluated DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Updated DataFrame with evaluation metrics and semantic scores.\n",
    "    \"\"\"\n",
    "    # Step 1: Evaluate responses\n",
    "    eval_df = evaluate_responses(data_frame, evaluator)\n",
    "    \n",
    "    # Step 2: Drop unnecessary columns\n",
    "    eval_df = eval_df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "    # Step 3: Compute semantic scores\n",
    "    reference = \"answer\"\n",
    "    response = \"generated_answer\"\n",
    "    cosine_similarities_bge, _ = semscore.compute_sem_score(data_frame, model_name=model_name, reference=reference, response=response)\n",
    "    eval_df[\"SemScore\"] = cosine_similarities_bge[\"Cosine_Similarity\"]\n",
    "\n",
    "    # Step 4: Merge original DataFrame with evaluation metrics\n",
    "    merged_df = pd.concat([data_frame, eval_df], axis=1)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = process_evaluation_and_metrics(\n",
    "    data_frame=df, \n",
    "    model_name='BAAI/bge-m3'\n",
    ")\n",
    "\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the filtered dataframe to a CSV file\n",
    "eval_df.to_csv('ResultsOnTestset/Baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_average_value(df, output_file):\n",
    "    # Compute the averages\n",
    "    mean_rouge = df['ROUGE-1'].mean()\n",
    "    mean_bert = df['BERT F1'].mean()\n",
    "    mean_sem = df['SemScore'].mean()\n",
    "\n",
    "    # Get model and other details\n",
    "    model = df['model'].unique()\n",
    "    chunking = df[\"chunking\"].unique()\n",
    "    preprocessing = df['preprocessing'].unique()\n",
    "    retriever = df['retriever'].unique()\n",
    "    advanced_techniques = df[\"advanced_techniques\"].unique()\n",
    "\n",
    "    # Create a dictionary of the results\n",
    "    results = {\n",
    "        'Model': model,\n",
    "        'Chunking': chunking,\n",
    "        'Preprocessing': preprocessing,\n",
    "        'Retriever': retriever,\n",
    "        'Advanced Techniques': advanced_techniques,\n",
    "        'Mean ROUGE-1': mean_rouge,\n",
    "        'Mean BERT F1': mean_bert,\n",
    "        'Mean SemScore': mean_sem\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    results_df = pd.DataFrame([results])\n",
    "\n",
    "    # Append the results to the CSV file (if it exists, otherwise create a new one)\n",
    "    results_df.to_csv(output_file, mode='a', header=not pd.io.common.file_exists(output_file), index=False)\n",
    "\n",
    "    # Print the results (optional)\n",
    "    print(\"Model:\", model, \"with chunking of type:\", chunking, \"that uses\", \n",
    "          preprocessing, retriever, advanced_techniques)\n",
    "    print(f\"Mean ROUGE-1: {mean_rouge}\")\n",
    "    print(f\"Mean BERT F1: {mean_bert}\")\n",
    "    print(f\"Mean SemScore: {mean_sem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_value(eval_df, \"ResultsMeanScore/Baseline.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_bianca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
